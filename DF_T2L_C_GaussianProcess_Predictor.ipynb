{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DF_T2L-C_GaussianProcess_Predictor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNVgOFxSJFa0F5lxBJRxUlt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JRopes/CrystalEnergyPredictionWithInvariants/blob/main/DF_T2L_C_GaussianProcess_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDj5sN2roJh6"
      },
      "source": [
        "**SETUP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggWnyNBSoBza",
        "outputId": "e205b007-4227-42d7-bf2c-9af325e3e0e5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwbvc3nToRML"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/drive/MyDrive/Colab_Notebooks/Dissertation/Prediction_Prototyping') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6Zru38ioRyS"
      },
      "source": [
        "**IMPORTING LIBRARY DEPENDENCIES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QRukFu9oV58"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import math\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bufgP6sVoYYk"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel, RationalQuadratic, RBF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLKMwi5koZgU"
      },
      "source": [
        "import DataImporter\n",
        "import DataPreprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stOItgojodKj"
      },
      "source": [
        "**IMPORTING DATA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sftuwe_Fomia",
        "outputId": "89c4f8ec-c213-4d9b-b91e-4d9f0e935d4d"
      },
      "source": [
        "feature_dir_path = '/content/drive/MyDrive/Colab_Notebooks/Dissertation/Data/T2L'\n",
        "label_file_path = '/content/drive/MyDrive/Colab_Notebooks/Dissertation/Data/T2L_density_energy.csv' \n",
        "\n",
        "(feature_data, label_data, x_labels) = DataImporter.DataFrameImport(feature_dir_path,label_file_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File with greatest Domain: T2L_Centres_03386.csv || Number of Density Functions: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNBjHCgWopBO"
      },
      "source": [
        "feature_data = DataPreprocessing.DataFiller(feature_data,feature_data[1,1,0],feature_data[1,0,200])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSy13oM6oqaK"
      },
      "source": [
        "pickle.dump(feature_data, open(\"feature_data_gp.p\", \"wb\"))\n",
        "\n",
        "pickle.dump(label_data, open(\"label_data_gp.p\",\"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_apNi6HotL4"
      },
      "source": [
        "def data():\n",
        "\n",
        "  feature_data = pickle.load(open(\"feature_data_gp.p\",\"rb\"))\n",
        "  label_data = pickle.load(open(\"label_data_gp.p\",\"rb\"))\n",
        "\n",
        "  shape = feature_data.shape\n",
        "\n",
        "  serial_feature_data = np.zeros((shape[0],(shape[1] * shape[2])))\n",
        "\n",
        "  df_length = np.ma.size(feature_data,2)\n",
        "\n",
        "  for i in range(shape[0]):\n",
        "    for j in range(shape[1]):\n",
        "      for z in range(shape[2]):\n",
        "              \n",
        "        serial_feature_data[i,((j * df_length) + z)] = feature_data[i,j,z]\n",
        "\n",
        "\n",
        "  pure_label_data = np.zeros((len(label_data)))\n",
        "\n",
        "  for i in range(len(label_data)):\n",
        "    pure_label_data[i] = label_data[i][1]\n",
        "\n",
        "  serial_feature_data = np.nan_to_num(serial_feature_data)\n",
        "\n",
        "  ## Standard Scaler\n",
        "  feature_scaler = preprocessing.StandardScaler()\n",
        "  label_scaler = preprocessing.StandardScaler()\n",
        "\n",
        "  X_scaled = (feature_scaler.fit_transform(serial_feature_data))\n",
        "  y_scaled = label_scaler.fit_transform(pure_label_data.reshape(-1,1))\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.1, shuffle=True)\n",
        "\n",
        "  return X_train, y_train, X_test, y_test, label_scaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhgMtQ_0pNrL"
      },
      "source": [
        "**ARCHITECTURE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz8MBYuhpQgO"
      },
      "source": [
        "kernel = RationalQuadratic() + RBF()\n",
        "\n",
        "gpr = GaussianProcessRegressor(kernel=kernel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAIkyr1pphjz"
      },
      "source": [
        "**TRAINING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nkTBdaKpdYK"
      },
      "source": [
        "X_train, y_train, X_test, y_test, label_scaler = data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3V2e7WgpsIR",
        "outputId": "d7601f78-77bf-4b0e-fca9-4dc97ee60c3a"
      },
      "source": [
        "gpr.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/gaussian_process/_gpr.py:494: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=RationalQuadratic(alpha=1, length_scale=1) + RBF(length_scale=1),\n",
              "                         n_restarts_optimizer=0, normalize_y=False,\n",
              "                         optimizer='fmin_l_bfgs_b', random_state=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tooRsBaOpyw6"
      },
      "source": [
        "**EVALUATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpRVdnqdp03l"
      },
      "source": [
        "predictions = gpr.predict(X_test).reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYvgkySXp7Yj"
      },
      "source": [
        "predictions = label_scaler.inverse_transform(predictions)\n",
        "y_test = label_scaler.inverse_transform(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC6Ut-IHqI6G",
        "outputId": "6ffd5fd0-e5f4-4ce4-9deb-7fccd6ed5177"
      },
      "source": [
        "average_loss = 0\n",
        "average_loss_percentage = 0\n",
        "average_loss_percentage_rel_range = 0\n",
        "counter = 0\n",
        "rms = 0\n",
        "\n",
        "error_ranges = np.array((0,0,0,0,0,0))\n",
        "\n",
        "max_value = -999999.99\n",
        "min_value = 999999.99\n",
        "\n",
        "for label in y_test:\n",
        "    if(label > max_value):\n",
        "        max_value = label\n",
        "        \n",
        "    if(label < min_value):\n",
        "        min_value = label\n",
        "        \n",
        "label_range = abs(max_value - min_value)\n",
        "\n",
        "\n",
        "for i,prediction in enumerate(predictions):\n",
        "    percentage_difference = abs((abs(prediction - y_test[i]) / y_test[i]) * 100)\n",
        "    percentage_difference2 = abs((abs(prediction - y_test[i]) / label_range) * 100)\n",
        "    loss = abs(prediction - y_test[i])\n",
        "    average_loss += loss\n",
        "\n",
        "    rms += loss**2\n",
        "\n",
        "    if(loss <= 1.0):\n",
        "      error_ranges[0] += 1\n",
        "    elif(loss <= 2.0):\n",
        "      error_ranges[1] += 1\n",
        "    elif(loss <= 4.0):\n",
        "      error_ranges[2] += 1\n",
        "    elif(loss <= 8.0):\n",
        "      error_ranges[3] += 1\n",
        "    elif(loss <= 10.0):\n",
        "      error_ranges[4] += 1\n",
        "    else:\n",
        "      error_ranges[5] += 1\n",
        "\n",
        "    average_loss_percentage += percentage_difference\n",
        "    average_loss_percentage_rel_range += percentage_difference2\n",
        "    counter += 1\n",
        "\n",
        "rms = math.sqrt(rms / counter)\n",
        "\n",
        "print()\n",
        "print(\"SUMMARY:\")\n",
        "print()\n",
        "print(\"Root Mean Squared Error: \" + str(rms))\n",
        "print(\"Mean Absolute Error: \" + str(average_loss / counter))\n",
        "print(\"Mean Absolute Percentage Error: \" + str(average_loss_percentage / counter) + \"%\")\n",
        "print(\"Mean Absolute Percentage Error relative to Label Range: \" + str(average_loss_percentage_rel_range / counter) + \"%\")\n",
        "print(\"Accuracy: \" + str(100 - (average_loss_percentage / counter)) + \"%\")\n",
        "print()\n",
        "print(\"BREAKDOWN:\")\n",
        "print(\"   Error <= 1.0 kJ/mol: \" + str(error_ranges[0]) + \" or \" + str((error_ranges[0] / counter) * 100) + \"% of Test Set\")\n",
        "print(\"   Error <= 2.0 kJ/mol: \" + str(error_ranges[1]) + \" or \" + str((error_ranges[1] / counter) * 100) + \"% of Test Set\")\n",
        "print(\"   Error <= 4.0 kJ/mol: \" + str(error_ranges[2]) + \" or \" + str((error_ranges[2] / counter) * 100) + \"% of Test Set\")\n",
        "print(\"   Error <= 8.0 kJ/mol: \" + str(error_ranges[3]) + \" or \" + str((error_ranges[3] / counter) * 100) + \"% of Test Set\")\n",
        "print(\"   Error <= 10.0.0 kJ/mol: \" + str(error_ranges[4]) + \" or \" + str((error_ranges[4] / counter) * 100) + \"% of Test Set\")\n",
        "print(\"   Error > 10.0 kJ/mol: \" + str(error_ranges[5]) + \" or \" + str((error_ranges[5] / counter) * 100) + \"% of Test Set\")\n",
        "print(\"----------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "SUMMARY:\n",
            "\n",
            "Root Mean Squared Error: 10.024285162144174\n",
            "Mean Absolute Error: [7.78401185]\n",
            "Mean Absolute Percentage Error: [5.54107664]%\n",
            "Mean Absolute Percentage Error relative to Label Range: [12.31984681]%\n",
            "Accuracy: [94.45892336]%\n",
            "\n",
            "BREAKDOWN:\n",
            "   Error <= 1.0 kJ/mol: 56 or 9.859154929577464% of Test Set\n",
            "   Error <= 2.0 kJ/mol: 41 or 7.21830985915493% of Test Set\n",
            "   Error <= 4.0 kJ/mol: 90 or 15.845070422535212% of Test Set\n",
            "   Error <= 8.0 kJ/mol: 148 or 26.056338028169012% of Test Set\n",
            "   Error <= 10.0.0 kJ/mol: 63 or 11.091549295774648% of Test Set\n",
            "   Error > 10.0 kJ/mol: 170 or 29.929577464788732% of Test Set\n",
            "----------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}