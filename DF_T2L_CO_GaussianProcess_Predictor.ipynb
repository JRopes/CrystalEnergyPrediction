{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DF_T2L-CO_GaussianProcess_Predictor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOcn307mVwEoUuZFtyYckZl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JRopes/CrystalEnergyPredictionWithInvariants/blob/main/DF_T2L_CO_GaussianProcess_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDj5sN2roJh6"
      },
      "source": [
        "**SETUP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggWnyNBSoBza",
        "outputId": "2b2fa5cc-86f6-44ca-9b62-2ff639929f3d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwbvc3nToRML"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/drive/MyDrive/Colab_Notebooks/Dissertation/Prediction_Prototyping') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6Zru38ioRyS"
      },
      "source": [
        "**IMPORTING LIBRARY DEPENDENCIES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QRukFu9oV58"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import math\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bufgP6sVoYYk"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel, RationalQuadratic, RBF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLKMwi5koZgU"
      },
      "source": [
        "import DataImporter_CO\n",
        "import DataPreprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stOItgojodKj"
      },
      "source": [
        "**IMPORTING DATA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sftuwe_Fomia",
        "outputId": "f127f6f3-60b2-48e5-a942-35675878ce1b"
      },
      "source": [
        "feature_dir_path = '/content/drive/MyDrive/Colab_Notebooks/Dissertation/Data/T2L_CO'\n",
        "label_file_path = '/content/drive/MyDrive/Colab_Notebooks/Dissertation/Data/T2L_density_energy.csv' \n",
        "\n",
        "(feature_data, label_data, x_labels) = DataImporter_CO.DataFrameImport(feature_dir_path,label_file_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File with greatest Domain: T2L_CO_03404.csv || Number of Density Functions: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNBjHCgWopBO"
      },
      "source": [
        "feature_data = DataPreprocessing.DataFiller(feature_data,feature_data[1,1,0],feature_data[1,0,48])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSy13oM6oqaK"
      },
      "source": [
        "pickle.dump(feature_data, open(\"feature_data_gaussian.p\", \"wb\"))\n",
        "\n",
        "pickle.dump(label_data, open(\"label_data_gaussian.p\",\"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_apNi6HotL4"
      },
      "source": [
        "def data():\n",
        "\n",
        "  feature_data = pickle.load(open(\"feature_data_gaussian.p\",\"rb\"))\n",
        "  label_data = pickle.load(open(\"label_data_gaussian.p\",\"rb\"))\n",
        "\n",
        "  shape = feature_data.shape\n",
        "\n",
        "  serial_feature_data = np.zeros((shape[0],(shape[1] * shape[2])))\n",
        "\n",
        "  df_length = np.ma.size(feature_data,2)\n",
        "\n",
        "  for i in range(shape[0]):\n",
        "    for j in range(shape[1]):\n",
        "      for z in range(shape[2]):\n",
        "              \n",
        "        serial_feature_data[i,((j * df_length) + z)] = feature_data[i,j,z]\n",
        "\n",
        "\n",
        "  pure_label_data = np.zeros((len(label_data)))\n",
        "\n",
        "  for i in range(len(label_data)):\n",
        "    pure_label_data[i] = label_data[i][1]\n",
        "\n",
        "  serial_feature_data = np.nan_to_num(serial_feature_data)\n",
        "\n",
        "  ## Standard Scaler\n",
        "  feature_scaler = preprocessing.StandardScaler()\n",
        "  label_scaler = preprocessing.StandardScaler()\n",
        "\n",
        "  X_scaled = (feature_scaler.fit_transform(serial_feature_data))\n",
        "  y_scaled = label_scaler.fit_transform(pure_label_data.reshape(-1,1))\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.1,shuffle=True)\n",
        "\n",
        "  return X_train, y_train, X_test, y_test, label_scaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhgMtQ_0pNrL"
      },
      "source": [
        "**ARCHITECTURE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz8MBYuhpQgO"
      },
      "source": [
        "kernel = RationalQuadratic() + RBF()\n",
        "\n",
        "gpr = GaussianProcessRegressor(kernel=kernel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAIkyr1pphjz"
      },
      "source": [
        "**TRAINING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nkTBdaKpdYK"
      },
      "source": [
        "X_train, y_train, X_test, y_test, label_scaler = data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3V2e7WgpsIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34574d69-ca47-4435-8b99-4317e643e1a4"
      },
      "source": [
        "gpr.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=RationalQuadratic(alpha=1, length_scale=1) + RBF(length_scale=1),\n",
              "                         n_restarts_optimizer=0, normalize_y=False,\n",
              "                         optimizer='fmin_l_bfgs_b', random_state=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tooRsBaOpyw6"
      },
      "source": [
        "**EVALUATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpRVdnqdp03l"
      },
      "source": [
        "predictions = gpr.predict(X_test).reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYvgkySXp7Yj"
      },
      "source": [
        "predictions = label_scaler.inverse_transform(predictions)\n",
        "y_test = label_scaler.inverse_transform(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC6Ut-IHqI6G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6214ea98-7fee-4e01-82a5-bb4c4c76dce8"
      },
      "source": [
        "average_loss = 0\n",
        "average_loss_percentage = 0\n",
        "average_loss_percentage_rel_range = 0\n",
        "counter = 0\n",
        "rms = 0\n",
        "\n",
        "error_ranges = np.array((0,0,0,0,0,0))\n",
        "\n",
        "max_value = -999999.99\n",
        "min_value = 999999.99\n",
        "\n",
        "for label in y_test:\n",
        "    if(label > max_value):\n",
        "        max_value = label\n",
        "        \n",
        "    if(label < min_value):\n",
        "        min_value = label\n",
        "        \n",
        "label_range = abs(max_value - min_value)\n",
        "\n",
        "\n",
        "for i,prediction in enumerate(predictions):\n",
        "    percentage_difference = abs((abs(prediction - y_test[i]) / y_test[i]) * 100)\n",
        "    percentage_difference2 = abs((abs(prediction - y_test[i]) / label_range) * 100)\n",
        "    loss = abs(prediction - y_test[i])\n",
        "    average_loss += loss\n",
        "\n",
        "    rms += loss**2\n",
        "\n",
        "    if(loss <= 1.0):\n",
        "      error_ranges[0] += 1\n",
        "    elif(loss <= 2.0):\n",
        "      error_ranges[1] += 1\n",
        "    elif(loss <= 4.0):\n",
        "      error_ranges[2] += 1\n",
        "    elif(loss <= 8.0):\n",
        "      error_ranges[3] += 1\n",
        "    elif(loss <= 10.0):\n",
        "      error_ranges[4] += 1\n",
        "    else:\n",
        "      error_ranges[5] += 1\n",
        "\n",
        "    average_loss_percentage += percentage_difference\n",
        "    average_loss_percentage_rel_range += percentage_difference2\n",
        "    counter += 1\n",
        "\n",
        "rms = math.sqrt(rms / counter)\n",
        "\n",
        "print()\n",
        "print(\"SUMMARY:\")\n",
        "print()\n",
        "print(\"Root Mean Squared Error: \" + str(rms))\n",
        "print(\"Mean Absolute Error: \" + str(average_loss / counter))\n",
        "print(\"Mean Absolute Percentage Error: \" + str(average_loss_percentage / counter) + \"%\")\n",
        "print(\"Mean Absolute Percentage Error relative to Label Range: \" + str(average_loss_percentage_rel_range / counter) + \"%\")\n",
        "print(\"Accuracy: \" + str(100 - (average_loss_percentage / counter)) + \"%\")\n",
        "print()\n",
        "print(\"BREAKDOWN:\")\n",
        "print(\"   Error <= 1.0 kJ/mol: \" + str(error_ranges[0]) + \" or \" + str((error_ranges[0] / counter) * 100) + \"% of Test Set\")\n",
        "print(\"   Error <= 2.0 kJ/mol: \" + str(error_ranges[1]) + \" or \" + str((error_ranges[1] / counter) * 100) + \"% of Test Set\")\n",
        "print(\"   Error <= 4.0 kJ/mol: \" + str(error_ranges[2]) + \" or \" + str((error_ranges[2] / counter) * 100) + \"% of Test Set\")\n",
        "print(\"   Error <= 8.0 kJ/mol: \" + str(error_ranges[3]) + \" or \" + str((error_ranges[3] / counter) * 100) + \"% of Test Set\")\n",
        "print(\"   Error <= 10.0.0 kJ/mol: \" + str(error_ranges[4]) + \" or \" + str((error_ranges[4] / counter) * 100) + \"% of Test Set\")\n",
        "print(\"   Error > 10.0 kJ/mol: \" + str(error_ranges[5]) + \" or \" + str((error_ranges[5] / counter) * 100) + \"% of Test Set\")\n",
        "print(\"----------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "SUMMARY:\n",
            "\n",
            "Root Mean Squared Error: 9.385253645119766\n",
            "Mean Absolute Error: [7.077118]\n",
            "Mean Absolute Percentage Error: [5.04241131]%\n",
            "Mean Absolute Percentage Error relative to Label Range: [7.44154536]%\n",
            "Accuracy: [94.95758869]%\n",
            "\n",
            "BREAKDOWN:\n",
            "   Error <= 1.0 kJ/mol: 64 or 11.267605633802818% of Test Set\n",
            "   Error <= 2.0 kJ/mol: 52 or 9.15492957746479% of Test Set\n",
            "   Error <= 4.0 kJ/mol: 111 or 19.54225352112676% of Test Set\n",
            "   Error <= 8.0 kJ/mol: 141 or 24.823943661971832% of Test Set\n",
            "   Error <= 10.0.0 kJ/mol: 52 or 9.15492957746479% of Test Set\n",
            "   Error > 10.0 kJ/mol: 148 or 26.056338028169012% of Test Set\n",
            "----------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}