{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DF_T2L-CO_RandomForest_Predictor.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOYAht9vckVU3gtGokWGFk+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JRopes/CrystalEnergyPredictionWithInvariants/blob/main/DF_T2L_CO_RandomForest_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OnC4lJS_pIM"
      },
      "source": [
        "**SETUP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2D3BAbS_ggk",
        "outputId": "30c95865-dd8b-4f21-a777-8341485aaff0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU4qRk8E_t1L"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/drive/MyDrive/Colab_Notebooks/Dissertation/Prediction_Prototyping') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz46ObCT_vrG"
      },
      "source": [
        "**IMPORTING LIBRARY DEPENDENCIES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9OWd6P9AATi"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import math\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE4Ebhaz_53E"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Akj35ZiXAH3E"
      },
      "source": [
        "import DataImporter_CO\n",
        "import DataPreprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhvBK6CPAKxD"
      },
      "source": [
        "**IMPORTING DATA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPpI90CxANia",
        "outputId": "cfb635ae-e153-417e-d778-53ad667121ff"
      },
      "source": [
        "feature_dir_path = '/content/drive/MyDrive/Colab_Notebooks/Dissertation/Data/T2L_CO'\n",
        "label_file_path = '/content/drive/MyDrive/Colab_Notebooks/Dissertation/Data/T2L_density_energy.csv' \n",
        "\n",
        "(feature_data, label_data, x_labels) = DataImporter_CO.DataFrameImport(feature_dir_path,label_file_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File with greatest Domain: T2L_CO_03404.csv || Number of Density Functions: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdWRO1BFA99z"
      },
      "source": [
        "feature_data = DataPreprocessing.DataFiller(feature_data,feature_data[1,1,0],feature_data[1,0,48])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSyeAMrgBAFN"
      },
      "source": [
        "pickle.dump(feature_data, open(\"feature_data_forest.p\", \"wb\"))\n",
        "\n",
        "pickle.dump(label_data, open(\"label_data_forest.p\",\"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlyQfk9PBDk7"
      },
      "source": [
        "def data():\n",
        "\n",
        "  feature_data = pickle.load(open(\"feature_data_forest.p\",\"rb\"))\n",
        "  label_data = pickle.load(open(\"label_data_forest.p\",\"rb\"))\n",
        "\n",
        "  shape = feature_data.shape\n",
        "\n",
        "  serial_feature_data = np.zeros((shape[0],(shape[1] * shape[2])))\n",
        "\n",
        "  df_length = np.ma.size(feature_data,2)\n",
        "\n",
        "  for i in range(shape[0]):\n",
        "    for j in range(shape[1]):\n",
        "      for z in range(shape[2]):\n",
        "              \n",
        "        serial_feature_data[i,((j * df_length) + z)] = feature_data[i,j,z]\n",
        "\n",
        "\n",
        "  pure_label_data = np.zeros((len(label_data)))\n",
        "\n",
        "  for i in range(len(label_data)):\n",
        "    pure_label_data[i] = label_data[i][1]\n",
        "\n",
        "  serial_feature_data = np.nan_to_num(serial_feature_data)\n",
        "\n",
        "  ## Standard Scaler\n",
        "  feature_scaler = preprocessing.StandardScaler()\n",
        "\n",
        "  X_scaled = (feature_scaler.fit_transform(serial_feature_data))\n",
        "  X_scaled = preprocessing.normalize(X_scaled, norm='l2')\n",
        "\n",
        "  y_scaled = pure_label_data.reshape(-1,1)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.1, shuffle=True)\n",
        "\n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWwQlLkzCUaG"
      },
      "source": [
        "**ARCHITECTURE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iED6A5yJCW8K"
      },
      "source": [
        "random_forest = RandomForestRegressor(n_estimators=400, criterion='mse', max_samples=0.95, n_jobs=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uss9ZsC6Cmn5"
      },
      "source": [
        "**TRAINING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTb0BSTDCy4Z"
      },
      "source": [
        "X_train, y_train, X_test, y_test = data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36i3vh7ECrEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf637d1-93ca-4c31-fba1-2736c01bf7bd"
      },
      "source": [
        "random_forest.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=0.95, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=400, n_jobs=-1, oob_score=False,\n",
              "                      random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y6Zbh6cDYN3"
      },
      "source": [
        "**EVALUATING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA6HofzMDato"
      },
      "source": [
        "predictions = random_forest.predict(X_test).reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kty-ouDLDgeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "721a7cdb-9b02-48a2-cef8-72e3d9beffc5"
      },
      "source": [
        "average_loss = 0\n",
        "average_loss_percentage = 0\n",
        "average_loss_percentage_rel_range = 0\n",
        "counter = 0\n",
        "rms = 0\n",
        "\n",
        "error_ranges = np.array((0,0,0,0,0,0))\n",
        "\n",
        "max_value = -999999.99\n",
        "min_value = 999999.99\n",
        "\n",
        "for label in y_test:\n",
        "    if(label > max_value):\n",
        "        max_value = label\n",
        "        \n",
        "    if(label < min_value):\n",
        "        min_value = label\n",
        "        \n",
        "label_range = abs(max_value - min_value)\n",
        "\n",
        "\n",
        "for i,prediction in enumerate(predictions):\n",
        "    percentage_difference = abs((abs(prediction - y_test[i]) / y_test[i]) * 100)\n",
        "    percentage_difference2 = abs((abs(prediction - y_test[i]) / label_range) * 100)\n",
        "    loss = abs(prediction - y_test[i])\n",
        "    average_loss += loss\n",
        "\n",
        "    rms += loss**2\n",
        "\n",
        "    if(loss <= 1.0):\n",
        "      error_ranges[0] += 1\n",
        "    elif(loss <= 2.0):\n",
        "      error_ranges[1] += 1\n",
        "    elif(loss <= 4.0):\n",
        "      error_ranges[2] += 1\n",
        "    elif(loss <= 8.0):\n",
        "      error_ranges[3] += 1\n",
        "    elif(loss <= 10.0):\n",
        "      error_ranges[4] += 1\n",
        "    else:\n",
        "      error_ranges[5] += 1\n",
        "\n",
        "    average_loss_percentage += percentage_difference\n",
        "    average_loss_percentage_rel_range += percentage_difference2\n",
        "    counter += 1\n",
        "\n",
        "rms = math.sqrt(rms / counter)\n",
        "\n",
        "print()\n",
        "print(\"SUMMARY:\")\n",
        "print()\n",
        "print(\"Root Mean Squared Error: \" + str(rms))\n",
        "print(\"Mean Absolute Error: \" + str(average_loss / counter))\n",
        "print(\"Mean Absolute Percentage Error: \" + str(average_loss_percentage / counter) + \"%\")\n",
        "print(\"Mean Absolute Percentage Error relative to Label Range: \" + str(average_loss_percentage_rel_range / counter) + \"%\")\n",
        "print(\"Accuracy: \" + str(100 - (average_loss_percentage / counter)) + \"%\")\n",
        "print()\n",
        "print(\"BREAKDOWN:\")\n",
        "print(\"   Error <= 1.0 kJ/mol: \" + str(error_ranges[0]) + \" or \" + str((error_ranges[0] / counter) * 100) + \"% of Test Set\")\n",
        "print(\"   Error <= 2.0 kJ/mol: \" + str(error_ranges[1]) + \" or \" + str((error_ranges[1] / counter) * 100) + \"% of Test Set\")\n",
        "print(\"   Error <= 4.0 kJ/mol: \" + str(error_ranges[2]) + \" or \" + str((error_ranges[2] / counter) * 100) + \"% of Test Set\")\n",
        "print(\"   Error <= 8.0 kJ/mol: \" + str(error_ranges[3]) + \" or \" + str((error_ranges[3] / counter) * 100) + \"% of Test Set\")\n",
        "print(\"   Error <= 10.0.0 kJ/mol: \" + str(error_ranges[4]) + \" or \" + str((error_ranges[4] / counter) * 100) + \"% of Test Set\")\n",
        "print(\"   Error > 10.0 kJ/mol: \" + str(error_ranges[5]) + \" or \" + str((error_ranges[5] / counter) * 100) + \"% of Test Set\")\n",
        "print(\"----------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "SUMMARY:\n",
            "\n",
            "Root Mean Squared Error: 9.36024696473878\n",
            "Mean Absolute Error: [7.45085172]\n",
            "Mean Absolute Percentage Error: [5.3272386]%\n",
            "Mean Absolute Percentage Error relative to Label Range: [12.07885165]%\n",
            "Accuracy: [94.6727614]%\n",
            "\n",
            "BREAKDOWN:\n",
            "   Error <= 1.0 kJ/mol: 39 or 6.866197183098592% of Test Set\n",
            "   Error <= 2.0 kJ/mol: 43 or 7.570422535211267% of Test Set\n",
            "   Error <= 4.0 kJ/mol: 100 or 17.6056338028169% of Test Set\n",
            "   Error <= 8.0 kJ/mol: 176 or 30.985915492957744% of Test Set\n",
            "   Error <= 10.0.0 kJ/mol: 66 or 11.619718309859154% of Test Set\n",
            "   Error > 10.0 kJ/mol: 144 or 25.352112676056336% of Test Set\n",
            "----------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}